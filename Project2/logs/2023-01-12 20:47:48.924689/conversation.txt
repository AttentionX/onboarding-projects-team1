Hello. Can I ask some questions?
 I understand the information. I'm ready to answer the questions.
What is the self-attention?
 Self-attention is an attention mechanism that relates different positions of a single sequence in order to compute a representation of the sequence. It is used to map one variable-length sequence of symbol representations to another sequence of equal length. It has a total computational complexity per layer and the amount of computation that can be parallelized is measured by the minimum number of sequential operations required. It is also used to learn long-range dependencies in the network by reducing the path length between long-range dependencies.
Can you explain that by the math?
 The self-attention mechanism is a way of computing a representation of a sequence by relating different positions of the sequence to each other. It is computed by taking the dot product of the query with all the keys, dividing each by the dimension of the keys, and applying a softmax function to obtain the weights on the values. This allows every position in the decoder to attend over all positions in the input sequence. The encoder contains self-attention layers, where all of the keys, values and queries come from the same place, in this case, the output of the previous layer in the encoder. The positional encoding is used to allow the model to easily learn to attend by relative positions, since for any fixed offset k, the positional encoding can be represented as a linear function of the positional encoding.
What is the limitation of the paper?
 The limitation of the paper is that it only performs a small number of experiments to select the dropout, both attention and residual, learning rates and beam size on the Section 22 development set. Additionally, the self-attention mechanism is limited in its ability to consider long-range dependencies in the network, as the maximum path length is O(n). To improve computational performance for tasks involving very long sequences, self-attention could be restricted to considering only a neighborhood of size r in the input sequence centered around the respective output position.
So model build with only self-attention have restricted input length?
 Models built with only self-attention have a restricted input length, as the maximum path length is O(n). To improve computational performance for tasks involving very long sequences, self-attention could be restricted to considering only a neighborhood of size r in the input sequence centered around the respective output position. This would increase the maximum path length to O(n/r). Additionally, the paper suggests that a more sophisticated compatibility function than dot product may be beneficial in determining compatibility.
Thank you. You helped me a lot.
 I understand the information. I'm ready to answer the questions.
Can you score the paper between 0 to 5 like making the paper review?
 Based on the information provided, I would rate the paper a 5 out of 5. The paper provides a new simple network architecture, the Transformer, based solely on attention mechanisms, which is superior in quality while being more parallelizable and requiring significantly less time to train. The paper also provides detailed experiments to evaluate the importance of different components of the Transformer, and the results show that the Transformer generalizes well to other tasks.
